<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title><![CDATA[de部落格^_^]]></title>
  <subtitle><![CDATA[Keep Blogging，keep trying，never give up~]]></subtitle>
  <link href="/atom.xml" rel="self"/>
  <link href="http://zhonghuan.com/"/>
  <updated>2014-09-04T05:58:11.605Z</updated>
  <id>http://zhonghuan.com/</id>
  
  <author>
    <name><![CDATA[钟桓]]></name>
    <email><![CDATA[zhonghuanblog@163.com]]></email>
  </author>
  
  <generator uri="http://zespia.tw/hexo/">Hexo</generator>
  
  <entry>
    <title><![CDATA[python网络爬虫学习笔记]]></title>
    <link href="http://zhonghuan.com/2014/09/04/python%E7%BD%91%E7%BB%9C%E7%88%AC%E8%99%AB%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    <id>http://zhonghuan.com/2014/09/04/python网络爬虫学习笔记/</id>
    <published>2014-09-03T20:38:11.000Z</published>
    <updated>2014-09-04T05:09:34.000Z</updated>
    <content type="html"><![CDATA[<h2 id="介绍：">介绍：</h2>
<p>网络爬虫的名字很有意思，英文名称web spider。真得很形象，蜘蛛结网为了获取食物，而我们的爬虫程序，也是为了获取网络上的资源。这篇blog是本人学习过程中的记录。学习过程中，使用的语言是python2.7；python2.7有两个模块，urllib和urllib2，这两个模块提供了很好的网络访问的功能。下面会更好的体会。值得一提的时，在python3中，将urllib和urllib2这两个模块合为一个urllib。感兴趣的可以看<a href="https://docs.python.org/3.4/howto/urllib2.html" target="_blank" rel="external">这里</a></p>
<p>urllib和urllib2是python中功能强大得网络工作库，它们让你的网络访问像文件访问一样（例如，文件访问我们要先open()一个文件，它的操作也是类似的，后面就会看到例子）。之所以能够这么方便，因为这些模块的内部很好的使用不同的网络协议来完成这些功能，（学过网络应该了解，访问一个网页这个简单的过程，其实涉及到很多的网络协议，像http，dns等等，而urllib和urllib2封装了这些协议，让我们不用和它们打交道，只需要调用这些模块的方法来完成我们需要的功能）。同时，这些模块也提供一些稍微更复杂一点的借口来处理一些情形，例如用户认证，cookies和代理等等。下面让我们开始来学习它们吧。</p>
<hr>
<h2 id="从简单语句中开始:">从简单语句中开始:</h2>
<p>前面说过，使用两个模块，访问网页变得就会像访问文件一样方便。在一般情况下，urllib2访问会更好些（效率上更好，不过urllib还是需要使用，后面会介绍需要urllib做一些事情），所以下面我们来看看使用urllib2的最简单的例子。</p>
<pre><code><span class="title">import</span> urllib2;

<span class="title">response</span> = urllib2.urlopen(<span class="string">"http://www.zhonghuan.info"</span>);
<span class="title">html</span> = response.read();
<span class="title">print</span> html;
</code></pre><p>在终端下下输入命令行  python test.py &gt; zhonghuan.html ,<br>打开文件后显示的是我的个人blog首页的html代码：</p>
<p><img style="width:100%" alt="" src="http://zhonghuan.qiniudn.com/python%2Fwebspider%2Fwebspider2.png"> </p>
<p>这是最简单的一个利用urllib2访问网页的例子，urllib2是根据URL中:前面的部分来判断是用什么协议访问的，例如，上面的例子我们用的时http，这里也可以换成ftp:,file:,等。。。我们可以不用去了解它内部是如何封装这些网络协议的。</p>
<p>urllib2中可以用一个镜像对象（Request Object）来表示我们http访问，它标示你想要访问的URL地址，我们来看一下下面的例子。</p>
<pre><code><span class="built_in">import</span> urllib2

<span class="variable">req =</span> urllib2.Request('http://www.zhonghuan.info')
<span class="variable">response =</span> urllib2.urlopen(req)
<span class="variable">the_page =</span> response.read()
print(the_page)
</code></pre><p>req变量就是一个Request对象。它确切的标示了你要访问的URL地址。（这里是<a href="http://www.zhonghuan.info）；对于其它的形式的访问，例如ftp和file，形式也是类似的，具体可以看[这里][2" target="_blank" rel="external">http://www.zhonghuan.info）；对于其它的形式的访问，例如ftp和file，形式也是类似的，具体可以看[这里][2</a>];</p>
<p>其实，Request对象还能做两个额外的事情。</p>
<ol>
<li>你可以发送数据给服务器。</li>
<li>你可以发送一些额外的信息（又叫元数据，描述数据的数据。一些语言里面的元类是生成类的类，如python就在这些语言中；所以元数据，顾名思义，描述数据的数据，那么这些被描述的数据是什么呢？上面中，还有request对象的一些信息，而这些描述被放在http头部发送出去了。有关http header，可以看<a href="http://en.wikipedia.org/wiki/List_of_HTTP_header_fields" target="_blank" rel="external">这里</a>）;</li>
</ol>
<hr>
<h2 id="传送数据给服务器">传送数据给服务器</h2>
<p>有时候，你需要发送数据给服务器，这个地址是URL表示的，通常呢，这个地址的指向是CGI（Common Gateway Interface）脚本或者是其它一些网络应用。（关于CGI脚本,可以看<a href="http://www.jdon.com/idea/cgi.htm" target="_blank" rel="external">这里</a>，简单的说就是处理上传数据的脚本程序）。在HTTP访问中，通常使用哪个POST方式将数据发送出去，就好像你填完了html中得表单，你需要把表单中得数据发送出去，通常这里使用post请求。当然，post使用还有其它的情况，不单单指的是表单这一种情况。</p>
<p>让我们先看下面的代码：</p>
<pre><code>import urllib
import urllib2

url = <span class="string">'http://www.someserver.com/cgi-bin/register.cgi'</span>
<span class="keyword">values</span> = {<span class="string">'name'</span> : <span class="string">'Michael Foord'</span>,
      <span class="string">'location'</span> : <span class="string">'Northampton'</span>,
      <span class="string">'language'</span> : <span class="string">'Python'</span> }
data = urllib.urlencode(<span class="keyword">values</span>)  <span class="comment">#数据需要重新编码成合适的格式，这里使用的时urllib中得方法，因为urllib2中没有编码的方法</span>
req = urllib2.Request(url, data)  <span class="comment"># #这里将需要上传的数据，传递给了equest对象，作为它的参数</span>
response = urllib2.urlopen(req)
the_page = response.<span class="keyword">read</span>()
</code></pre><p>关于其它类型的数据上传，可以看<a href="http://www.w3.org/TR/REC-html40/interact/forms.html#h-17.13" target="_blank" rel="external">这里</a></p>
<p>除了使用post方式上传数据外，还可以使用get方式上传数据，get上传和post上传明显的区别就是get上传的数据会在URL中得尾部显示出来。可以看下面的代码：</p>
<hr>
<pre><code><span class="import"><span class="keyword">import</span> urllib</span>
<span class="import"><span class="keyword">import</span> urllib2</span>

<span class="typedef"><span class="keyword">data</span> = <span class="container">{}</span></span>
<span class="typedef"><span class="keyword">data</span>['name'] = '<span class="type">Somebody</span> <span class="type">Here'</span></span>
<span class="typedef"><span class="keyword">data</span>['location'] = '<span class="type">Northampton'</span></span>
<span class="typedef"><span class="keyword">data</span>['language'] = '<span class="type">Python'</span></span>

<span class="title">url_values</span> = urllib.urlencode(<span class="typedef"><span class="keyword">data</span>)</span>
<span class="title">print</span> url_values  # 这里的顺序不一定

<span class="title">url</span> = 'http://www.example.com/example.cgi'
<span class="title">full_url</span> = url + '?' + url_values
<span class="typedef"><span class="keyword">data</span> = urllib2.urlopen<span class="container">(<span class="title">full_url</span>)</span></span>
</code></pre><p>可以悄悄打印出来url_value的形式。</p>
<hr>
<h2 id="HTTP头—描述数据的数据">HTTP头—描述数据的数据</h2>
<p>现在，我们来讨论一下HTTP头，来看看如何在你的HTTP的Request对象，增加一个HTTP头。</p>
<p>有一些网站，它比较智能，它不喜欢被程序访问（非人为的点击只会加重它服务器的负担）。或者有些网站更加智能点，对于不同的浏览器，会发送不同的网页数据。</p>
<p>可是呢，urllib2默认,会这样标示自己，<code>Python-urllib/x.y</code>(其中，x和y分别是大小版本号，例如我现在使用的时<code>Python-urllib/2.7</code>);而这些数据可能会让一些站点觉得迷惑，要是遇上了不喜欢被程序访问的网站，那么这样的访问可能会直接被忽视。所以，你可以构造一些身份，让站点不会拒绝你。看下面的例子。</p>
<pre><code><span class="keyword">import</span> urllib
<span class="keyword">import</span> urllib2

url <span class="subst">=</span> <span class="string">'http://www.someserver.com/cgi-bin/register.cgi'</span>
user_agent <span class="subst">=</span> <span class="string">'Mozilla/4.0 (compatible; MSIE 5.5; Windows NT)'</span> <span class="variable">#user_agent</span>用来标示你的浏览器的，向这里就是mozilla
values <span class="subst">=</span> {<span class="string">'name'</span> : <span class="string">'Michael Foord'</span>,
      <span class="string">'location'</span> : <span class="string">'Northampton'</span>,
      <span class="string">'language'</span> : <span class="string">'Python'</span> }

headers <span class="subst">=</span> { <span class="string">'User-Agent'</span> : user_agent }
<span class="built_in">data</span> <span class="subst">=</span> urllib<span class="built_in">.</span>urlencode(values)

req <span class="subst">=</span> urllib2<span class="built_in">.</span>Request(url, <span class="built_in">data</span>, headers)

response <span class="subst">=</span> urllib2<span class="built_in">.</span>urlopen(req)

the_page <span class="subst">=</span> response<span class="built_in">.</span>read()    
</code></pre><hr>
<h2 id="异常">异常</h2>
<p>异常时常有，要小心提防呐！想想一般文件操作的时候，会有什么异常呢？文件无法打开，什么权限不够啊，文件不存在啊等等异常。同样的，对于URL访问，也会遇到这些问题，（python一些内部异常，例如ValueError，TypeError等异常，也可能会发生）</p>
<p><br></p>
<h4 id="URLError">URLError</h4>
<p>先说说URLError，当没有网络连接，或者访问的服务器地址不存在的时候，在这种情况下，URLError会被抛出来，这个时候，URLError异常会有个“reason”属性，它是一个元组，包含error code（int型）和text error message（string型），看下面的代码</p>
<pre><code><span class="keyword">import</span> urllib
<span class="keyword">import</span> urllib2


req = urllib2.Request(<span class="string">'http://www.pretend_server.org'</span>)
<span class="keyword">try</span>: urllib2.urlopen(req)
<span class="keyword">except</span> urllib2.URLError <span class="keyword">as</span> e:
    <span class="keyword">print</span> e.reason
</code></pre><p>输出<code>[Errno 8] nodename nor servname provided, or not known</code>;输出的内容就是reason，</p>
<p><br></p>
<h4 id="HTTPError">HTTPError</h4>
<p>每一个HTTP访问，会从服务器那儿获得一个“status code”（状态码），通常这些状态码告诉我们服务器无法满足一些访问（直白点说就是一些数据而已，只不过表示的是当前访问的状态，比如当前访问被拒绝了，status code可以告诉你，你哪些举动过分了，出格了，注意，咸猪手不可以有啊~~）。</p>
<p>不过呢，urllib2的默认处理器能够帮助你处理一些服务器的响应，比如说你当前访问的网址被服务器重定向了，就是说你的服务器给你一个新的URL访问了，处理器会帮你直接去访问新的URL。</p>
<p>但是默认的处理器毕竟功能有限，它不能帮助你解决所有问题，比如你访问的网站不存在了（对应404错误，我们有时候会看到这个错误），或者你的访问被禁止了（对应403错误，禁止的原因可能是因为你的权限不够啦等等），又或者是需要你验证啦（对应401）。具体的其它错误本文就不介绍啦，具体可以看<a href="http://baike.baidu.com/view/1399931.htm" target="_blank" rel="external">这里</a></p>
<p>让我们看下面的程序，看一下当HTTPError的404错误，也就是页面不存在时候，它会输出点什么。</p>
<pre><code><span class="keyword">import</span> urllib
<span class="keyword">import</span> urllib2


req = urllib2.Request(<span class="string">'http://www.zhonghuan.info/no_way'</span>)
<span class="keyword">try</span>: urllib2.urlopen(req)
<span class="keyword">except</span> urllib2.HTTPError <span class="keyword">as</span> e:
       <span class="keyword">print</span> e.code;
     <span class="keyword">print</span> e.read();         
</code></pre><p>输出：<br>404</p>
<p><code>&lt;!DOCTYPE html&gt;</code></p>
<p>…</p>
<p><code>&lt;title&gt;Page not found &amp;middot; GitHub Pages&lt;/title&gt;</code></p>
<p>…</p>
<p><br></p>
<h4 id="处理异常">处理异常</h4>
<p>假设你想要捕捉HTTPError和URLError，有两种基本的方法，推荐第二种噢！</p>
<p><strong>第一种：</strong></p>
<pre><code><span class="keyword">from</span> urllib2 <span class="keyword">import</span> Request, urlopen, URLError, HTTPError


req = Request(http://zhonghuan.info)
<span class="keyword">try</span>:
    response = urlopen(req)
<span class="keyword">except</span> HTTPError <span class="keyword">as</span> e:
    <span class="keyword">print</span> <span class="string">'The server couldn\'t fulfill the request.'</span>
    <span class="keyword">print</span> <span class="string">'Error code: '</span>, e.code
<span class="keyword">except</span> URLError <span class="keyword">as</span> e:
    <span class="keyword">print</span> <span class="string">'We failed to reach a server.'</span>
    <span class="keyword">print</span> <span class="string">'Reason: '</span>, e.reason
<span class="keyword">else</span>:
    <span class="comment"># everything is fine</span>
</code></pre><p>第一种方法，HTTPError一定要放在URLError前面，原因呢，和很多语言的异常处理机制一样，HTTPError是URLError的子类，如果发生了HTTPError，它可以被当做是URLError被捕捉。   </p>
<p><strong>第二种：</strong></p>
<pre><code><span class="keyword">from</span> urllib2 <span class="keyword">import</span> Request, urlopen, URLError


req = Request(someurl)
<span class="keyword">try</span>:
       response = urlopen(req)
<span class="keyword">except</span> URLError <span class="keyword">as</span> e:
    <span class="keyword">if</span> hasattr(e, <span class="string">'reason'</span>):
        <span class="keyword">print</span> <span class="string">'We failed to reach a server.'</span>
        <span class="keyword">print</span> <span class="string">'Reason: '</span>, e.reason
    <span class="keyword">elif</span> hasattr(e, <span class="string">'code'</span>):
        <span class="keyword">print</span> <span class="string">'The server couldn\'t fulfill the request.'</span>
        <span class="keyword">print</span> <span class="string">'Error code: '</span>, e.code
<span class="keyword">else</span>:
    <span class="comment"># everything is fine        </span>
</code></pre><p><br></p>
<h4 id="info和geturl">info和geturl</h4>
<p>这里介绍两个方法info()和geturl()；</p>
<p>geturl():该方法会返回访问的页面的真实的URL，它的价值在于我们访问的网页可能会被重定向，所以导致访问的URL和我们输入的可能不一样。看下面的例子：</p>
<pre><code><span class="preprocessor"><span class="keyword">import</span> urllib</span>
<span class="preprocessor"><span class="keyword">import</span> urllib2</span>

url = <span class="comment">'http://weibo.com/u/2103243911';</span>
req = urllib2.Request(url);
response = urllib2.urlopen(req)

<span class="built_in">print</span> <span class="string">"URL:"</span>,url;
<span class="built_in">print</span> <span class="string">"After redirection:"</span>,response.geturl();
</code></pre><p>以我的微博个人主页为例，其实真实访问被重定向了，真实的网址，从输出中可以看出:</p>
<p><code>URL: http://weibo.com/u/2103243911</code><br><br><code>After redirection: http://passport.weibo.com/visitor/visitor?a=enter&amp;url=http%3A%2F%2Fweibo.com%2Fu%2F2103243911&amp;_rand=1409761358.1794</code></p>
<p><br><br>info():可以得到描述页面的信息，返回的是一个<code>httplib.HTTPMessage</code>实例，打印出来很像字典。看下面的代码：</p>
<pre><code><span class="title">import</span> urllib
import urllib2


url = <span class="string">'http://zhonghuan.info'</span>;
<span class="title">req</span> = urllib2.Request(url);
<span class="title">response</span> = urllib2.urlopen(req);
<span class="title">print</span> response.<span class="built_in">info</span>();
<span class="title">print</span> response.<span class="built_in">info</span>().__class__;
</code></pre><p>输出：</p>
<pre><code><span class="attribute">Server</span>: <span class="string">GitHub.com</span>
<span class="attribute">Content-Type</span>: <span class="string">text/html; charset=utf-8</span>
<span class="attribute">Last-Modified</span>: <span class="string">Tue, 02 Sep 2014 17:01:39 GMT</span>
<span class="attribute">Expires</span>: <span class="string">Wed, 03 Sep 2014 15:23:02 GMT</span>
<span class="attribute">Cache-Control</span>: <span class="string">max-age=600</span>
<span class="attribute">Content-Length</span>: <span class="string">4784</span>
<span class="attribute">Accept-Ranges</span>: <span class="string">bytes</span>
<span class="attribute">Date</span>: <span class="string">Wed, 03 Sep 2014 16:38:29 GMT</span>
<span class="attribute">Via</span>: <span class="string">1.1 varnish</span>
<span class="attribute">Age</span>: <span class="string">5127</span>
<span class="attribute">Connection</span>: <span class="string">close</span>
<span class="attribute">X-Served-By</span>: <span class="string">cache-lax1433-LAX</span>
<span class="attribute">X-Cache</span>: <span class="string">HIT</span>
<span class="attribute">X-Cache-Hits</span>: <span class="string">1</span>
<span class="attribute">X-Timer</span>: <span class="string">S1409762309.465760,VS0,VE0</span>
<span class="attribute">Vary</span>: <span class="string">Accept-Encoding</span>

<span class="http"><span class="attribute">Class</span>: <span class="string">httplib.HTTPMessage</span></span>
</code></pre><hr>
<p><br></p>
<h2 id="Opener和Handler">Opener和Handler</h2>
<p>这里介绍Opener和Handler。</p>
<p>什么是Opener呢？其实上面的例子我们一直在用Opener了，就是urlopen。这个是默认的opener，网络访问情况很多，你可以创建比较合适的opener，</p>
<p>什么是Handler呢？其实Opener会调用Handler来处理访问中得琐事，所以Handler很重要，对于特定的协议（例如FTP，HTTP），它知道如何如何处理访问，例如它会帮你处理重定向问题。</p>
<p>在访问的时候，你可能对于Opener有一些要求，例如，你希望得到的Opener能够处理cookie，或者你不希望Opener帮助你处理重定向。</p>
<p>我们如何生成需要得Opener呢？（这里插一下，个人觉得这里的Opener生成方式，和设计模式中得生成器欧式，又叫建造者模式，英文名称Builder Pattern；有些相似，不过不完全一样，但总觉得，在看下去之前，先了解一下这个模式会有好处，没有接触过的朋友可以看这篇<a href="http://blog.csdn.net/zhonghuan1992/article/details/38418139" target="_blank" rel="external">Builder pattern</a>）;</p>
<p>要创建一个 opener，可以实例化一个OpenerDirector，<br>然后调用.add_handler(some_handler_instance)。</p>
<p>不过，可以使用build_opener，这是一个更加方便的函数，用来创建opener对象，他只需要一次函数调用。build_opener默认添加几个处理器，但提供快捷的方法来添加或更新默认处理器。<br>其他的处理器handlers你或许会希望处理代理，验证，和其他常用但有点特殊的情况。</p>
<p>刚刚提到handler会帮我们处理重定向，但是，如果我们不想要重定向呢，该怎么办，自定义一个handler。看下面的代码：</p>
<pre><code>mport urllib
<span class="keyword">import</span> urllib2


<span class="class"><span class="keyword">class</span> <span class="title">RedirectHandler</span><span class="params">(urllib2.HTTPRedirectHandler)</span>:</span><span class="comment"># 这个RedirectHandler继承了HTTPRedirectHandler，不过，它覆盖了父类的方法，让它什么都不做，失去了重定向的功能。</span>
    <span class="function"><span class="keyword">def</span> <span class="title">http_error_301</span><span class="params">(self, req, fp, code, msg, headers)</span>:</span>
        <span class="keyword">pass</span>
    <span class="function"><span class="keyword">def</span> <span class="title">http_error_302</span><span class="params">(self, req, fp, code, msg, headers)</span>:</span>
        <span class="keyword">pass</span>


webo = <span class="string">"http://weibo.com/u/2103243911"</span>; <span class="comment">#访问的是我的微博页面，因为正常情况下，访问时会发生重定向</span>
opener = urllib2.build_opener(RedirectHandler) <span class="comment">#这里，我们自定义了一个opener，添加了一个重定向时处理的自定义handler</span>
response = opener.open(webo);<span class="comment"># response  = urllib2.urlopen(webo);</span>
<span class="keyword">print</span> response.geturl();
urllib2.install_opener(opener);  <span class="comment">#安装自定义的opener，以后调用urllib2的时候，返回的就是这个opener。</span>
</code></pre><p>输出结果是：<br><code>urllib2.HTTPError: HTTP Error 302: Moved Temporarily</code></p>
<p>之所以发生http error 302，是因为本来访问我的微博个人主页的时候，它应该发生重定向的，可是我们自己的重定向Handler什么都不做，结果就是发生异常了。</p>
<p>可以看看下面的urllib2关于创建自定义Opener的类图</p>
<p><br><br><img src="http://zhonghuan.qiniudn.com/python%2Fwebspider%2Fwebspider3.gif" alt=""></p>
<hr>
<p><br></p>
<h2 id="Basic_Authentication">Basic Authentication</h2>
<p>如果一个网站，他提供注册登入这些功能，那么一般它有用户名/密码,如果你访问的页面，系统要求你提供用户名/密码，这个过程叫做Authentication，实在服务器那端所做的操作。它给一些页面提供了安全保护。</p>
<p>一个基本的Authentication（验证）过程是这样的：</p>
<ol>
<li>客户端提出请求访问某些页面。</li>
<li>服务器返回一个错误，要求进行身份验证。</li>
<li>客户端把用户名/密码（一般这样）编码后发给服务器。</li>
<li>服务器检查这对用户名/密码是否正确，然后返回用户请求的页面或者是一些错误。</li>
</ol>
<p>上面的过程，还有可能是其它形式，这里只是举个比较普遍的。</p>
<p>通常服务器返回的是401错误，表明访问的网页未授权，同时，返回的response的header内有形如</p>
<p><code>WWW-Authenticate: SCHEME realm=&quot;REALM&quot;.</code></p>
<p>的内容，例如，你想要访问cPanel的管理应用程序，你会收到这样的header：<code>WWW-Authenticate: Basic realm=&quot;cPanel&quot;</code>（cPanel 是一套在网页寄存业中最享负盛名的商业软件，其基于 Linux 和 BSD 系统及以 PHP 开发且性质为闭源软件；cPanel 主要是面向客户权级的控制系统）</p>
<p>当我们访问页面的时候，opener会调用handler来处理各种情况，而处理Authentication的handler是urllib2.HTTPBasicAuthHandler，同时需要一个用户密码管理器urllib2.HTTPPasswordMgr。</p>
<p>不幸的时，HTTPPasswordMgr有一个小问题，就是在获取网页前，你需要知道它的realm。幸运的是，它有一个表兄弟HTTPPasswordMgrWithDefaultRealm，这个表兄弟可以事先不知道realm，在realm参数位置上，可以传一个None进去，它更友好的被使用。</p>
<p>下面参考下面的代码：</p>
<pre><code><span class="built_in">import</span> urllib2


<span class="variable">url =</span> 'http://www.weibo.com'<span class="comment">#分别对应域名，账号，密码</span>
<span class="variable">username =</span> 'zhonghuan'
<span class="variable">password =</span> 'forget_it'
<span class="variable">passman =</span> urllib2.HTTPPasswordMgrWithDefaultRealm() <span class="comment">#创建密码管理器</span>
passman.add_password(None, url, username, password)<span class="comment"># 参数形式（realm，URL，UserName，Password）</span>
<span class="variable">authhandler =</span> urllib2.HTTPBasicAuthHandler(passman)<span class="comment">#创建Authentication的handler</span>
<span class="variable">opener =</span> urllib2.build_opener(authhandler)
urllib2.install_opener(opener) <span class="comment">#和上面介绍的一样，install_opener后，每次调用urllib2的urlopen，返回的就是这个opener</span>
<span class="variable">pagehandle =</span> urllib2.urlopen(url)
</code></pre><hr>
<p><br></p>
<h2 id="代理">代理</h2>
<p>有时候，我们本机不能直接访问，需要代理服务器去访问。urllib2对这个设置代理支持的还不错，可以直接实例化ProxyHandler，它的参数是一个map，key值是代理的访问协议名称，value值是代理的地址。看下面的代码实现。</p>
<pre><code><span class="built_in">import</span> urllib2


<span class="variable">enable_proxy =</span> True
<span class="variable">proxy_handler =</span> urllib2.ProxyHandler({<span class="string">"http"</span> : 'http://some-proxy.com:<span class="number">8080</span>'})
<span class="variable">null_proxy_handler =</span> urllib2.ProxyHandler({})
<span class="keyword">if</span> enable_proxy:
    <span class="variable">opener =</span> urllib2.build_opener(proxy_handler)
<span class="keyword">else</span>:
    <span class="variable">opener =</span> urllib2.build_opener(null_proxy_handler)
urllib2.install_opener(opener)
</code></pre><hr>
<p><br></p>
<h2 id="Timeout_设置">Timeout 设置</h2>
<p>在老版 Python 中，urllib2 的 API 并没有暴露 Timeout 的设置，要设置 Timeout 值，只能更改 Socket 的全局 Timeout 值。</p>
<pre><code><span class="preprocessor"><span class="keyword">import</span> urllib2</span>
<span class="preprocessor"><span class="keyword">import</span> socket</span>


socket.setdefaulttimeout(<span class="number">10</span>)<span class="preprocessor"> # 10 秒钟后超时</span>
urllib2.socket.setdefaulttimeout(<span class="number">10</span>)<span class="preprocessor"> # 另一种方式</span>
</code></pre><p>在 Python 2.6 以后，超时可以通过 urllib2.urlopen() 的 timeout 参数直接设置。</p>
<pre><code><span class="built_in">import</span> urllib2

<span class="variable">response =</span> urllib2.urlopen('http://www.google.com', <span class="variable">timeout=</span><span class="number">10</span>)
</code></pre><hr>
<p><br></p>
<h2 id="Cookie">Cookie</h2>
<p>urllib2 对 Cookie 的处理也是自动的。如果需要得到某个 Cookie 项的值，可以这么做：</p>
<pre><code>import urllib2
import cookielib


cookie = cookielib.CookieJar()
opener = urllib2.build_opener(urllib2.HTTPCookieProcessor(cookie))
response = opener.<span class="built_in">open</span>(<span class="string">'http://www.google.com'</span>)
<span class="keyword">for</span> <span class="keyword">item</span> <span class="operator">in</span> cookie:
    <span class="keyword">if</span> <span class="keyword">item</span>.name == <span class="string">'some_cookie_item_name'</span>:
        print <span class="keyword">item</span>.<span class="built_in">value</span>
</code></pre><hr>
<p><br></p>
<h2 id="Debug_Log">Debug Log</h2>
<p>使用 urllib2 时，可以通过下面的方法把 debug Log 打开，这样收发包的内容就会在屏幕上打印出来，方便调试，有时可以省去抓包的工作</p>
<pre><code><span class="built_in">import</span> urllib2


<span class="variable">httpHandler =</span> urllib2.HTTPHandler(<span class="variable">debuglevel=</span><span class="number">1</span>)
<span class="variable">httpsHandler =</span> urllib2.HTTPSHandler(<span class="variable">debuglevel=</span><span class="number">1</span>)
<span class="variable">opener =</span> urllib2.build_opener(httpHandler, httpsHandler)
urllib2.install_opener(opener)
<span class="variable">response =</span> urllib2.urlopen('http://www.google.com')
</code></pre><hr>
<h2 id="参考资料：">参考资料：</h2>
<ol>
<li><p><a href="https://docs.python.org/2.7/howto/urllib2.html" target="_blank" rel="external">python urllib2的使用</a> <strong>(推荐)</strong></p>
</li>
<li><p><a href="http://blog.csdn.net/column/details/why-bug.html" target="_blank" rel="external">python网络爬虫入门教程</a> <strong>(推荐)</strong> </p>
</li>
<li><p><a href="http://www.jdon.com/idea/cgi.htm" target="_blank" rel="external">CGI脚本入门</a> <strong>(推荐)</strong></p>
</li>
<li><p><a href="http://daoluan.net/blog/urllib2-source-decode/" target="_blank" rel="external">urllib2 源码小剖</a> </p>
</li>
<li><p><a href="http://zhuoqiang.me/python-urllib2-usage.html" target="_blank" rel="external">Python 标准库 urllib2 的使用细节</a> <strong>(推荐)</strong></p>
</li>
<li><p><a href="http://www.voidspace.org.uk/python/articles/authentication.shtml" target="_blank" rel="external">Authentication with Python</a> <strong>(推荐)</strong></p>
</li>
<li><p><a href="http://en.wikipedia.org/wiki/List_of_HTTP_header_fields" target="_blank" rel="external">http://en.wikipedia.org/wiki/List_of_HTTP_header_fields</a></p>
</li>
</ol>
<hr>
]]></content>
    
    
      <category term="python" scheme="http://zhonghuan.com/tags/python/"/>
    
      <category term="webspider" scheme="http://zhonghuan.com/tags/webspider/"/>
    
      <category term="urllib" scheme="http://zhonghuan.com/tags/urllib/"/>
    
      <category term="urllib2" scheme="http://zhonghuan.com/tags/urllib2/"/>
    
      <category term="python网络爬虫" scheme="http://zhonghuan.com/categories/webspider/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[Hello World]]></title>
    <link href="http://zhonghuan.com/2014/09/01/hello-world/"/>
    <id>http://zhonghuan.com/2014/09/01/hello-world/</id>
    <published>2014-09-01T08:28:04.000Z</published>
    <updated>2014-09-01T08:28:04.000Z</updated>
    <content type="html"><![CDATA[<p>Welcome to <a href="http://hexo.io/" target="_blank" rel="external">Hexo</a>! This is your very first post. Check <a href="http://hexo.io/docs/" target="_blank" rel="external">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="http://hexo.io/docs/troubleshooting.html" target="_blank" rel="external">trobuleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="external">GitHub</a>.</p>
<h2 id="Quick_Start">Quick Start</h2>
<h3 id="Create_a_new_post">Create a new post</h3>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ hexo new <span class="string">"My New Post"</span></div></pre></td></tr></table></figure>

<p>More info: <a href="http://hexo.io/docs/writing.html" target="_blank" rel="external">Writing</a></p>
<h3 id="Run_server">Run server</h3>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ hexo server</div></pre></td></tr></table></figure>

<p>More info: <a href="http://hexo.io/docs/server.html" target="_blank" rel="external">Server</a></p>
<h3 id="Generate_static_files">Generate static files</h3>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ hexo generate</div></pre></td></tr></table></figure>

<p>More info: <a href="http://hexo.io/docs/generating.html" target="_blank" rel="external">Generating</a></p>
<h3 id="Deploy_to_remote_sites">Deploy to remote sites</h3>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ hexo deploy</div></pre></td></tr></table></figure>

<p>More info: <a href="http://hexo.io/docs/deployment.html" target="_blank" rel="external">Deployment</a></p>
]]></content>
    
    
  </entry>
  
</feed>
